{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13a3e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8226ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData1 = np.load('data_12_14_2023_16_14_27.npy')\n",
    "rawData2 = np.load('data_12_14_2023_16_16_41.npy')\n",
    "data1 = np.array([frame[\"adcSamples\"][:, 128:] for frame in rawData1])\n",
    "data2 = np.array([frame[\"adcSamples\"][:, 128:] for frame in rawData2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be2b398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_norm(matrix):\n",
    "    msum = np.sum(matrix)\n",
    "    return matrix / msum\n",
    "\n",
    "def get_highest_n_idxs(idxs, heights, n):\n",
    "    srtd_idxs = np.argsort(heights['peak_heights'])\n",
    "    return idxs[srtd_idxs][:n]\n",
    "\n",
    "def avg_dist(array):\n",
    "    if len(array) == 1:\n",
    "        return array[0]\n",
    "    total = 0\n",
    "    for i in range(len(array) - 1):\n",
    "        total += abs(array[i] - array[i+1])\n",
    "    return total / (len(array) - 1)\n",
    "\n",
    "def get_avg_peak_idxs_dist(peaks_list):\n",
    "    total = 0\n",
    "    for peaks in peaks_list:\n",
    "        total += avg_dist(peaks)\n",
    "    return total / len(peaks_list)\n",
    "\n",
    "def get_num_values(list_of_lists):\n",
    "    total = 0\n",
    "    for vals in list_of_lists:\n",
    "        total += len(vals)\n",
    "    return total\n",
    "\n",
    "num_peaks = 10\n",
    "def get_features(matrix):\n",
    "    norm_matrix = l1_norm(matrix)\n",
    "    matrix_mean = np.mean(norm_matrix)\n",
    "    matrix_std = np.std(norm_matrix)\n",
    "    horiz_peak_idxs_list = []\n",
    "    horiz_peaks_list = []\n",
    "    vert_peak_idxs_list = []\n",
    "    vert_peaks_list = []\n",
    "    for i in range(matrix.shape[0]):\n",
    "        horiz_peak_idxs, horiz_peaks = find_peaks(norm_matrix[i], height=(matrix_mean + matrix_std))\n",
    "        horiz_peaks_list.append(horiz_peaks['peak_heights'])\n",
    "        horiz_peak_idxs_list.append(get_highest_n_idxs(horiz_peak_idxs, horiz_peaks, num_peaks))\n",
    "    for i in range(matrix.shape[1]):\n",
    "        vert_peak_idxs, vert_peaks = find_peaks(norm_matrix[:, i], height=(matrix_mean + matrix_std))\n",
    "        vert_peaks_list.append(vert_peaks['peak_heights'])\n",
    "        vert_peak_idxs_list.append(get_highest_n_idxs(vert_peak_idxs, vert_peaks, num_peaks))\n",
    "    \n",
    "    num_horiz_peaks = get_num_values(horiz_peak_idxs_list)\n",
    "    num_vert_peaks = get_num_values(vert_peak_idxs_list)\n",
    "    features = [\n",
    "        get_avg_peak_idxs_dist(horiz_peak_idxs_list),  # average horizontal peak idx distance\n",
    "        get_avg_peak_idxs_dist(vert_peak_idxs_list),   # average vertical peak idx distance\n",
    "        num_horiz_peaks                                # stringiness\n",
    "    ]\n",
    "    return features\n",
    "\n",
    "def divide_data_matrix(whole_matrix, bit_chirp_size):\n",
    "    bit_matrices = np.array_split(whole_matrix, len(whole_matrix) // bit_chirp_size)\n",
    "    return bit_matrices\n",
    "\n",
    "data1_f = data1[:, 0, :]\n",
    "data2_f = data2[:, 0, :]\n",
    "\n",
    "labelled_data = []\n",
    "print(\"Forward and Back\")\n",
    "bit_matrices = divide_data_matrix(data1_f, 20)\n",
    "for bit_matrix in bit_matrices:\n",
    "    fft1_range = np.abs(np.fft.fft(bit_matrix, axis=1))[:, 15:64]\n",
    "    fft1_vel = np.abs(np.fft.fft(fft1_range, axis=0))[:, :]\n",
    "    labelled_data.append([get_features(fft1_range), 1])\n",
    "    print(get_features(fft1_range))\n",
    "\n",
    "print(\"Side to Side\")\n",
    "bit_matrices = divide_data_matrix(data2_f, 20)\n",
    "for bit_matrix in bit_matrices:\n",
    "    fft2_range = np.abs(np.fft.fft(bit_matrix, axis=1))[:, 15:64]\n",
    "    fft2_vel = np.abs(np.fft.fft(fft2_range, axis=0))[:, :]\n",
    "    labelled_data.append([get_features(fft2_range), 0])\n",
    "    print(get_features(fft2_range))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 40))\n",
    "ax[0].imshow(l1_norm(fft1_range), cmap='inferno', aspect='auto')\n",
    "ax[0].set_title(\"Forward and Back\")\n",
    "ax[0].set_ylabel(\"Chirps\")\n",
    "ax[0].set_xlabel(\"Range Bin\")\n",
    "ax[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "ax[1].imshow(l1_norm(fft2_range), cmap='inferno', aspect='auto')\n",
    "ax[1].set_title(\"Side to Side\")\n",
    "ax[1].set_ylabel(\"Chirps\")\n",
    "ax[1].set_xlabel(\"Range Bin\")\n",
    "ax[1].set_aspect('equal', adjustable='box')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d42af2",
   "metadata": {},
   "source": [
    "**Writing Train Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67869b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y  = [], []\n",
    "# for i in range(len(labelled_data)):\n",
    "#     X.append(labelled_data[i][0])\n",
    "#     y.append(labelled_data[i][1])\n",
    "\n",
    "\n",
    "# with open('test_labels.txt', 'w') as f:\n",
    "#     for i in y:\n",
    "#         f.write(f'{i}\\n')\n",
    "# with open('test_features.txt', 'w') as f:\n",
    "#     for i in X:\n",
    "#         f.write(str(i) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43913a",
   "metadata": {},
   "source": [
    "**Reading Train Files**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9df2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "with open('train_labels.txt', 'r') as f:\n",
    "    y = f.readlines()\n",
    "\n",
    "with open('features.txt', 'r') as f:\n",
    "    X = f.readlines()\n",
    "\n",
    "for i in range(len(X)):\n",
    "    if X[i][-1] == '\\n':\n",
    "        X[i] = X[i][:len(X[i])-1]\n",
    "    X[i] = ast.literal_eval(X[i])\n",
    "    X[i] = np.array(X[i])\n",
    "    \n",
    "    y[i] = int(y[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2465dae1",
   "metadata": {},
   "source": [
    "**Training SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19c670b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X)    \n",
    "y_train = np.array(y)\n",
    "\n",
    "clf = SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216a04d0",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aefd18ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_string_by_length(input_string, chunk_length):\n",
    "    return [input_string[i:i+chunk_length] for i in range(0, len(input_string), chunk_length)]\n",
    "\n",
    "def binary_to_string(bits):\n",
    "    string = split_string_by_length(bits, 8)\n",
    "    return ''.join([chr(int(i, 2)) for i in string])\n",
    "\n",
    "values = '0110100001100101011011000110110001101111'\n",
    "binary_to_string(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485972cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_summary(features, predictions, real):\n",
    "    print(f'Features: {features}, Prediction: {predictions[0]}, Real: {real}')\n",
    "def show_accuracy(predicted, real):\n",
    "    print(f'Accuracy: {accuracy_score(predicted, real) * 100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bdc1fb",
   "metadata": {},
   "source": [
    "**Test Set Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45b4e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_labels.txt', 'r') as f:\n",
    "    test_values = f.read().replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27055140",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_features.txt', 'r') as f:\n",
    "    features = f.readlines()\n",
    "\n",
    "for i in range(len(features)):\n",
    "    if features[i][-1] == '\\n':\n",
    "        features[i] = features[i][:len(features[i])-1]\n",
    "    features[i] = ast.literal_eval(features[i])\n",
    "    features[i] = np.array(features[i])\n",
    "\n",
    "features = np.array(features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5952570b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(features)\n",
    "test_list = list(test_values)\n",
    "for i in range(len(test_list)):\n",
    "    test_list[i] = int(test_list[i])\n",
    "test_list = np.array(test_list)\n",
    "show_accuracy(y_pred, test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0f17ed",
   "metadata": {},
   "source": [
    "**'hello' string test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50ce87ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawTestData = np.load('data_12_14_2023_17_36_04.npy')\n",
    "testData = np.array([frame[\"adcSamples\"][:, 128:] for frame in rawTestData])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d8b47c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testData_f = testData[:, 0, :]\n",
    "bit_matrices = divide_data_matrix(testData_f, 20)\n",
    "bin_values = '0110100001100101011011000110110001101111' # bits for 'hello', change for other target string\n",
    "\n",
    "final = []\n",
    "for i, bit_matrix in enumerate(bit_matrices):\n",
    "    fft1_range = np.abs(np.fft.fft(bit_matrix, axis=1))[:, 15:64]\n",
    "    features = get_features(fft1_range)\n",
    "    y_pred = clf.predict([features])\n",
    "    final.append(y_pred[0])\n",
    "    print_summary(features, y_pred, bin_values[i])\n",
    "print('\\n')\n",
    "\n",
    "bin_list = list(bin_values)\n",
    "for i in range(len(bin_list)):\n",
    "    bin_list[i] = int(bin_list[i])\n",
    "bin_list = np.array(bin_list)\n",
    "final = np.array(final)\n",
    "show_accuracy(bin_list, final)\n",
    "final_message = binary_to_string(''.join(str(i) for i in final))\n",
    "print(f'Decoded Message: {final_message}') #Ã£\u0011\u0010"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc451f",
   "metadata": {},
   "source": [
    "**Raspberry Pi- UDP Client**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719db947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "\n",
    "ip_addr = \"172.16.99.107\"    # IP address of Raspberry Pi 17, run udp_server.py on Pi\n",
    "port_num = 5000\n",
    "\n",
    "sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)  # UDP\n",
    "sock.sendto(bytes(final_message, \"utf-8\"), (ip_addr, port_num))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec9633",
   "metadata": {},
   "source": [
    "**Miscellaneous**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f3fbe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import TensorDataset, DataLoader\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# class Model(nn.Module):\n",
    "#     def __init__(self, input_size, output_size):\n",
    "#         super(Model, self).__init__()\n",
    "#         #self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "#         self.fc = nn.Linear(input_size, output_size)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         x = self.fc(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         return x.squeeze()\n",
    "\n",
    "# input_size = 3  # Number of features\n",
    "# output_size = 1 \n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
    "\n",
    "# model = Model(input_size, output_size)\n",
    "# criterion = nn.BCELoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# train_set = TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train))\n",
    "# train_loader = DataLoader(train_set, batch_size=40, shuffle=True)\n",
    "\n",
    "# num_epochs = 20\n",
    "\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "#     model.train()\n",
    "#     for features, labels in train_loader:\n",
    "#         outputs = model(features)\n",
    "#         print(outputs)\n",
    "#         print(labels)\n",
    "#         loss = criterion(outputs, labels)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa523920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.eval()\n",
    "# test_loss = 0\n",
    "# test_correct = 0\n",
    "# test_total = 0\n",
    "# threshold = 0.5\n",
    "# X_test = torch.Tensor(X_test)\n",
    "# y_test = torch.Tensor(y_test)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     test_outputs = model(X_test)\n",
    "\n",
    "# # Discretize the output using a threshold (e.g., 0.5)\n",
    "# threshold = 0.5\n",
    "# predicted_labels = (test_outputs > threshold).float()\n",
    "\n",
    "\n",
    "# # Calculate accuracy on the test set\n",
    "# accuracy = torch.sum(predicted_labels == y_test) / len(y_test)\n",
    "# print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "# print(f'Predicted: {predicted_labels}')\n",
    "# print(f'Real:      {y_test}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
